{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexes/datetimes.py:831: PerformanceWarning: Non-vectorized DateOffset being applied to Series or DatetimeIndex\n",
      "  \"or DatetimeIndex\", PerformanceWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loads = pd.read_csv('../data/clean/loads/HighLoads.csv')\n",
    "loads.head()\n",
    "loads['total'] = loads.sum(axis=1)\n",
    "loads.loc[loads['hour'] == 24, 'hour'] = 0\n",
    "loads.index = pd.to_datetime(loads[['year', 'month', 'day', 'hour']])\n",
    "last_year = loads.index.year[-1]\n",
    "loads.loc[loads['hour'] == 0].index += pd.DateOffset(day=1)\n",
    "#loads.loc[loads['year'] > last_year].index = loads.loc[loads['year'] > last_year].index.year - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def get_load_data(path='../data/clean/loads', filename='HighLoads.csv', corrections=True, \n",
    "                  total=False, *args, **kwargs):\n",
    "    \"\"\" Load consumption data\n",
    "    \n",
    "    TODO:\n",
    "    This could be a csv or it could connect to a DB.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(os.path.join(path, filename))\n",
    "    # Calculate the sum of loads\n",
    "    df['total'] = df.sum(axis=1)\n",
    "    # Convert to datetime if does not exist\n",
    "    last_year = df['year'].iloc[-1:].values\n",
    "    if corrections:\n",
    "        try:\n",
    "            df.loc[df['hour'] == 24, 'hour'] = 0\n",
    "            df.loc[df['hour'] == 0, 'hour'] +=  1\n",
    "            # Fix below code to represent a year regression\n",
    "            df.loc[df['year'] > last_year] -= pd.DateOffset(day=365)\n",
    "        except ValueError as e:\n",
    "            # TODO Add error if data is wrong\n",
    "            pass\n",
    "    df.index = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
    "    \n",
    "    if total:\n",
    "        df = df[['total']].sort_index()\n",
    "    return df.sort_index()\n",
    "\n",
    "loads = get_load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timepoints creation\n",
    "\n",
    "This is the part where you can change the time resolution of switch. Here you can define the number of timepoints you will use for the analysis. One easy approach, to do it automatically is to groupb the data by maximum per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>year_peakTime</th>\n",
       "      <th>month_peakTime</th>\n",
       "      <th>day_peakTime</th>\n",
       "      <th>hour_peakTime</th>\n",
       "      <th>01-hermosillo_peakTime</th>\n",
       "      <th>02-cananea_peakTime</th>\n",
       "      <th>03-obregon_peakTime</th>\n",
       "      <th>04-los_mochis_peakTime</th>\n",
       "      <th>05-culiacan_peakTime</th>\n",
       "      <th>06-mazatlan_peakTime</th>\n",
       "      <th>...</th>\n",
       "      <th>45-cozumel_peakTime</th>\n",
       "      <th>46-tijuana_peakTime</th>\n",
       "      <th>47-ensenada_peakTime</th>\n",
       "      <th>48-mexicali_peakTime</th>\n",
       "      <th>49-san_luis_rio_colorado_peakTime</th>\n",
       "      <th>50-villa_constitucion_peakTime</th>\n",
       "      <th>51-la_paz_peakTime</th>\n",
       "      <th>52-los_cabos_peakTime</th>\n",
       "      <th>53-mulege_peakTime</th>\n",
       "      <th>total_peakTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016-12-31</th>\n",
       "      <th>2016-01-31</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>2016-01-31 01:00:00</td>\n",
       "      <td>2016-01-01 23:00:00</td>\n",
       "      <td>2016-01-21 21:00:00</td>\n",
       "      <td>2016-01-21 21:00:00</td>\n",
       "      <td>2016-01-21 21:00:00</td>\n",
       "      <td>2016-01-21 21:00:00</td>\n",
       "      <td>2016-01-21 21:00:00</td>\n",
       "      <td>2016-01-21 21:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-01-13 19:00:00</td>\n",
       "      <td>2016-01-16 21:00:00</td>\n",
       "      <td>2016-01-16 21:00:00</td>\n",
       "      <td>2016-01-16 21:00:00</td>\n",
       "      <td>2016-01-16 21:00:00</td>\n",
       "      <td>2016-01-27 21:00:00</td>\n",
       "      <td>2016-01-27 21:00:00</td>\n",
       "      <td>2016-01-27 21:00:00</td>\n",
       "      <td>2016-01-16 21:00:00</td>\n",
       "      <td>2016-01-28 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-29</th>\n",
       "      <td>2016-02-01 01:00:00</td>\n",
       "      <td>2016-02-01 01:00:00</td>\n",
       "      <td>2016-02-29 01:00:00</td>\n",
       "      <td>2016-02-01 23:00:00</td>\n",
       "      <td>2016-02-27 21:00:00</td>\n",
       "      <td>2016-02-27 21:00:00</td>\n",
       "      <td>2016-02-27 21:00:00</td>\n",
       "      <td>2016-02-27 21:00:00</td>\n",
       "      <td>2016-02-27 21:00:00</td>\n",
       "      <td>2016-02-27 21:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-02-26 20:00:00</td>\n",
       "      <td>2016-02-20 21:00:00</td>\n",
       "      <td>2016-02-20 21:00:00</td>\n",
       "      <td>2016-02-20 21:00:00</td>\n",
       "      <td>2016-02-20 21:00:00</td>\n",
       "      <td>2016-02-17 21:00:00</td>\n",
       "      <td>2016-02-17 21:00:00</td>\n",
       "      <td>2016-02-17 21:00:00</td>\n",
       "      <td>2016-02-26 22:00:00</td>\n",
       "      <td>2016-02-25 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>2016-03-01 01:00:00</td>\n",
       "      <td>2016-03-01 01:00:00</td>\n",
       "      <td>2016-03-31 01:00:00</td>\n",
       "      <td>2016-03-01 23:00:00</td>\n",
       "      <td>2016-03-31 17:00:00</td>\n",
       "      <td>2016-03-31 17:00:00</td>\n",
       "      <td>2016-03-31 17:00:00</td>\n",
       "      <td>2016-03-31 17:00:00</td>\n",
       "      <td>2016-03-31 17:00:00</td>\n",
       "      <td>2016-03-31 17:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-28 20:00:00</td>\n",
       "      <td>2016-03-25 23:00:00</td>\n",
       "      <td>2016-03-25 23:00:00</td>\n",
       "      <td>2016-03-25 23:00:00</td>\n",
       "      <td>2016-03-25 23:00:00</td>\n",
       "      <td>2016-03-26 21:00:00</td>\n",
       "      <td>2016-03-26 21:00:00</td>\n",
       "      <td>2016-03-26 21:00:00</td>\n",
       "      <td>2016-03-07 21:00:00</td>\n",
       "      <td>2016-03-31 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-30</th>\n",
       "      <td>2016-04-01 01:00:00</td>\n",
       "      <td>2016-04-01 01:00:00</td>\n",
       "      <td>2016-04-30 01:00:00</td>\n",
       "      <td>2016-04-01 23:00:00</td>\n",
       "      <td>2016-04-29 18:00:00</td>\n",
       "      <td>2016-04-29 18:00:00</td>\n",
       "      <td>2016-04-29 18:00:00</td>\n",
       "      <td>2016-04-29 18:00:00</td>\n",
       "      <td>2016-04-29 18:00:00</td>\n",
       "      <td>2016-04-29 18:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-04-29 23:00:00</td>\n",
       "      <td>2016-04-21 17:00:00</td>\n",
       "      <td>2016-04-21 17:00:00</td>\n",
       "      <td>2016-04-21 17:00:00</td>\n",
       "      <td>2016-04-21 17:00:00</td>\n",
       "      <td>2016-04-25 22:00:00</td>\n",
       "      <td>2016-04-25 22:00:00</td>\n",
       "      <td>2016-04-25 22:00:00</td>\n",
       "      <td>2016-04-09 22:00:00</td>\n",
       "      <td>2016-04-29 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-31</th>\n",
       "      <td>2016-05-01 01:00:00</td>\n",
       "      <td>2016-05-01 01:00:00</td>\n",
       "      <td>2016-05-31 01:00:00</td>\n",
       "      <td>2016-05-01 23:00:00</td>\n",
       "      <td>2016-05-31 01:00:00</td>\n",
       "      <td>2016-05-31 01:00:00</td>\n",
       "      <td>2016-05-31 01:00:00</td>\n",
       "      <td>2016-05-31 01:00:00</td>\n",
       "      <td>2016-05-31 01:00:00</td>\n",
       "      <td>2016-05-31 01:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-05-28 23:00:00</td>\n",
       "      <td>2016-05-27 20:00:00</td>\n",
       "      <td>2016-05-27 20:00:00</td>\n",
       "      <td>2016-05-27 20:00:00</td>\n",
       "      <td>2016-05-27 20:00:00</td>\n",
       "      <td>2016-05-30 18:00:00</td>\n",
       "      <td>2016-05-30 18:00:00</td>\n",
       "      <td>2016-05-30 18:00:00</td>\n",
       "      <td>2016-05-16 15:00:00</td>\n",
       "      <td>2016-05-27 22:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            year_peakTime      month_peakTime  \\\n",
       "2016-12-31 2016-01-31 2016-01-01 01:00:00 2016-01-01 01:00:00   \n",
       "           2016-02-29 2016-02-01 01:00:00 2016-02-01 01:00:00   \n",
       "           2016-03-31 2016-03-01 01:00:00 2016-03-01 01:00:00   \n",
       "           2016-04-30 2016-04-01 01:00:00 2016-04-01 01:00:00   \n",
       "           2016-05-31 2016-05-01 01:00:00 2016-05-01 01:00:00   \n",
       "\n",
       "                             day_peakTime       hour_peakTime  \\\n",
       "2016-12-31 2016-01-31 2016-01-31 01:00:00 2016-01-01 23:00:00   \n",
       "           2016-02-29 2016-02-29 01:00:00 2016-02-01 23:00:00   \n",
       "           2016-03-31 2016-03-31 01:00:00 2016-03-01 23:00:00   \n",
       "           2016-04-30 2016-04-30 01:00:00 2016-04-01 23:00:00   \n",
       "           2016-05-31 2016-05-31 01:00:00 2016-05-01 23:00:00   \n",
       "\n",
       "                      01-hermosillo_peakTime 02-cananea_peakTime  \\\n",
       "2016-12-31 2016-01-31    2016-01-21 21:00:00 2016-01-21 21:00:00   \n",
       "           2016-02-29    2016-02-27 21:00:00 2016-02-27 21:00:00   \n",
       "           2016-03-31    2016-03-31 17:00:00 2016-03-31 17:00:00   \n",
       "           2016-04-30    2016-04-29 18:00:00 2016-04-29 18:00:00   \n",
       "           2016-05-31    2016-05-31 01:00:00 2016-05-31 01:00:00   \n",
       "\n",
       "                      03-obregon_peakTime 04-los_mochis_peakTime  \\\n",
       "2016-12-31 2016-01-31 2016-01-21 21:00:00    2016-01-21 21:00:00   \n",
       "           2016-02-29 2016-02-27 21:00:00    2016-02-27 21:00:00   \n",
       "           2016-03-31 2016-03-31 17:00:00    2016-03-31 17:00:00   \n",
       "           2016-04-30 2016-04-29 18:00:00    2016-04-29 18:00:00   \n",
       "           2016-05-31 2016-05-31 01:00:00    2016-05-31 01:00:00   \n",
       "\n",
       "                      05-culiacan_peakTime 06-mazatlan_peakTime  \\\n",
       "2016-12-31 2016-01-31  2016-01-21 21:00:00  2016-01-21 21:00:00   \n",
       "           2016-02-29  2016-02-27 21:00:00  2016-02-27 21:00:00   \n",
       "           2016-03-31  2016-03-31 17:00:00  2016-03-31 17:00:00   \n",
       "           2016-04-30  2016-04-29 18:00:00  2016-04-29 18:00:00   \n",
       "           2016-05-31  2016-05-31 01:00:00  2016-05-31 01:00:00   \n",
       "\n",
       "                              ...         45-cozumel_peakTime  \\\n",
       "2016-12-31 2016-01-31         ...         2016-01-13 19:00:00   \n",
       "           2016-02-29         ...         2016-02-26 20:00:00   \n",
       "           2016-03-31         ...         2016-03-28 20:00:00   \n",
       "           2016-04-30         ...         2016-04-29 23:00:00   \n",
       "           2016-05-31         ...         2016-05-28 23:00:00   \n",
       "\n",
       "                      46-tijuana_peakTime 47-ensenada_peakTime  \\\n",
       "2016-12-31 2016-01-31 2016-01-16 21:00:00  2016-01-16 21:00:00   \n",
       "           2016-02-29 2016-02-20 21:00:00  2016-02-20 21:00:00   \n",
       "           2016-03-31 2016-03-25 23:00:00  2016-03-25 23:00:00   \n",
       "           2016-04-30 2016-04-21 17:00:00  2016-04-21 17:00:00   \n",
       "           2016-05-31 2016-05-27 20:00:00  2016-05-27 20:00:00   \n",
       "\n",
       "                      48-mexicali_peakTime 49-san_luis_rio_colorado_peakTime  \\\n",
       "2016-12-31 2016-01-31  2016-01-16 21:00:00               2016-01-16 21:00:00   \n",
       "           2016-02-29  2016-02-20 21:00:00               2016-02-20 21:00:00   \n",
       "           2016-03-31  2016-03-25 23:00:00               2016-03-25 23:00:00   \n",
       "           2016-04-30  2016-04-21 17:00:00               2016-04-21 17:00:00   \n",
       "           2016-05-31  2016-05-27 20:00:00               2016-05-27 20:00:00   \n",
       "\n",
       "                      50-villa_constitucion_peakTime  51-la_paz_peakTime  \\\n",
       "2016-12-31 2016-01-31            2016-01-27 21:00:00 2016-01-27 21:00:00   \n",
       "           2016-02-29            2016-02-17 21:00:00 2016-02-17 21:00:00   \n",
       "           2016-03-31            2016-03-26 21:00:00 2016-03-26 21:00:00   \n",
       "           2016-04-30            2016-04-25 22:00:00 2016-04-25 22:00:00   \n",
       "           2016-05-31            2016-05-30 18:00:00 2016-05-30 18:00:00   \n",
       "\n",
       "                      52-los_cabos_peakTime  53-mulege_peakTime  \\\n",
       "2016-12-31 2016-01-31   2016-01-27 21:00:00 2016-01-16 21:00:00   \n",
       "           2016-02-29   2016-02-17 21:00:00 2016-02-26 22:00:00   \n",
       "           2016-03-31   2016-03-26 21:00:00 2016-03-07 21:00:00   \n",
       "           2016-04-30   2016-04-25 22:00:00 2016-04-09 22:00:00   \n",
       "           2016-05-31   2016-05-30 18:00:00 2016-05-16 15:00:00   \n",
       "\n",
       "                           total_peakTime  \n",
       "2016-12-31 2016-01-31 2016-01-28 20:00:00  \n",
       "           2016-02-29 2016-02-25 20:00:00  \n",
       "           2016-03-31 2016-03-31 21:00:00  \n",
       "           2016-04-30 2016-04-29 17:00:00  \n",
       "           2016-05-31 2016-05-27 22:00:00  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timepoints = loads.groupby([pd.TimeGrouper('A'), \n",
    "                                 pd.TimeGrouper('M')]).idxmax().add_suffix('_peakTime')\n",
    "timepoints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `timepoints` dataframe we can get the number of timepoints that will be used and the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of timepoints\n",
    "ts_num_tps = timepoints.groupby(level=[0]).size().unique()[0]\n",
    "ts_num_tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = timepoints['total_peakTime']\n",
    "dates;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will recreate a full day considering the maximum of each month. We will obtain `n`number of points in front and behind the timestamp of the maximum load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_day(data, number=4, freq='MS'):\n",
    "    \"\"\" Construc a representative day based on a single timestamp\n",
    "    # Month start is to avoid getting more timepoints in a even division\n",
    "    Args:\n",
    "    data\n",
    "    dates\n",
    "    number\n",
    "    Todo: Write readme\n",
    "    \"\"\"\n",
    "    years = []\n",
    "    if number & 1:\n",
    "        raise ValueError('Odd number of timepoints. Use even number')\n",
    "    for index, group in data.groupby([pd.TimeGrouper('A'), pd.TimeGrouper(freq=freq)]):\n",
    "        peak_timestamp = group.idxmax()\n",
    "        mask = peak_timestamp.strftime('%Y-%m-%d') \n",
    "        years.append(group.loc[mask].iloc[::int((24/4))].reset_index())    \n",
    "    output_data = pd.concat(years)\n",
    "    output_data.rename(columns={'index':'date', 'total':'peak_day'}, inplace=True)\n",
    "\n",
    "    return output_data\n",
    "\n",
    "peak_data = get_peak_day(loads['2016']['total'], freq='1MS') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>peak_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-28 01:00:00</td>\n",
       "      <td>29568.037637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-28 06:00:00</td>\n",
       "      <td>28171.708455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-28 12:00:00</td>\n",
       "      <td>34755.193564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-28 18:00:00</td>\n",
       "      <td>34800.964456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-25 01:00:00</td>\n",
       "      <td>33630.565561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date      peak_day\n",
       "0 2016-01-28 01:00:00  29568.037637\n",
       "1 2016-01-28 06:00:00  28171.708455\n",
       "2 2016-01-28 12:00:00  34755.193564\n",
       "3 2016-01-28 18:00:00  34800.964456\n",
       "0 2016-02-25 01:00:00  33630.565561"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 4\n",
    "def get_median_day(data, number=4, freq='1MS'):\n",
    "    years = []\n",
    "    for index, group in data.groupby([pd.TimeGrouper('A'), pd.TimeGrouper(freq)]):\n",
    "        grouper = group.groupby(pd.TimeGrouper('D')).mean()\n",
    "        if len(grouper) & 1:\n",
    "            # Odd number of days\n",
    "            index_median = grouper.loc[grouper==grouper.median()].index[0]\n",
    "        else:\n",
    "            # Even number of days\n",
    "            index_median = (np.abs(grouper-grouper.median())).argmin()\n",
    "        years.append(group.loc[index_median.strftime('%Y-%m-%d')].iloc[::int((24/number))].reset_index())\n",
    "    output_data = pd.concat(years)\n",
    "    output_data.rename(columns={'index':'date', 'total':'median_day'}, inplace=True)\n",
    "\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>median_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-09 01:00:00</td>\n",
       "      <td>31241.213088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-09 06:00:00</td>\n",
       "      <td>27394.188498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-09 12:00:00</td>\n",
       "      <td>33429.098094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-09 18:00:00</td>\n",
       "      <td>33316.666473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-05 01:00:00</td>\n",
       "      <td>30132.111645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date    median_day\n",
       "0 2016-01-09 01:00:00  31241.213088\n",
       "1 2016-01-09 06:00:00  27394.188498\n",
       "2 2016-01-09 12:00:00  33429.098094\n",
       "3 2016-01-09 18:00:00  33316.666473\n",
       "0 2016-02-05 01:00:00  30132.111645"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_data = get_median_day(loads['2016']['total'])\n",
    "median_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tab file\n",
    "\n",
    "### Timestamp\n",
    "\n",
    "The timestamp file needs to include the format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>peak_day</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>TIMESERIES</th>\n",
       "      <th>daysinmonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-28 01:00:00</td>\n",
       "      <td>29568.037637</td>\n",
       "      <td>2016012801</td>\n",
       "      <td>2016_01P</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-28 06:00:00</td>\n",
       "      <td>28171.708455</td>\n",
       "      <td>2016012806</td>\n",
       "      <td>2016_01P</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-28 12:00:00</td>\n",
       "      <td>34755.193564</td>\n",
       "      <td>2016012812</td>\n",
       "      <td>2016_01P</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-28 18:00:00</td>\n",
       "      <td>34800.964456</td>\n",
       "      <td>2016012818</td>\n",
       "      <td>2016_01P</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-25 01:00:00</td>\n",
       "      <td>33630.565561</td>\n",
       "      <td>2016022501</td>\n",
       "      <td>2016_02P</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date      peak_day   timestamp TIMESERIES  daysinmonth\n",
       "0 2016-01-28 01:00:00  29568.037637  2016012801   2016_01P           31\n",
       "1 2016-01-28 06:00:00  28171.708455  2016012806   2016_01P           31\n",
       "2 2016-01-28 12:00:00  34755.193564  2016012812   2016_01P           31\n",
       "3 2016-01-28 18:00:00  34800.964456  2016012818   2016_01P           31\n",
       "0 2016-02-25 01:00:00  33630.565561  2016022501   2016_02P           29"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_identifier = 'P'\n",
    "peak_data['timestamp'] = peak_data['date'].dt.strftime('%Y%m%d%H')\n",
    "peak_data['TIMESERIES'] = peak_data['date'].dt.strftime('%Y_%m{}'.format(peak_identifier))\n",
    "peak_data['daysinmonth'] = peak_data['date'].dt.daysinmonth\n",
    "peak_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>median_day</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>TIMESERIES</th>\n",
       "      <th>daysinmonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-09 01:00:00</td>\n",
       "      <td>31241.213088</td>\n",
       "      <td>2016010901</td>\n",
       "      <td>2016_01M</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-09 06:00:00</td>\n",
       "      <td>27394.188498</td>\n",
       "      <td>2016010906</td>\n",
       "      <td>2016_01M</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-09 12:00:00</td>\n",
       "      <td>33429.098094</td>\n",
       "      <td>2016010912</td>\n",
       "      <td>2016_01M</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-09 18:00:00</td>\n",
       "      <td>33316.666473</td>\n",
       "      <td>2016010918</td>\n",
       "      <td>2016_01M</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-05 01:00:00</td>\n",
       "      <td>30132.111645</td>\n",
       "      <td>2016020501</td>\n",
       "      <td>2016_02M</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date    median_day   timestamp TIMESERIES  daysinmonth\n",
       "0 2016-01-09 01:00:00  31241.213088  2016010901   2016_01M           31\n",
       "1 2016-01-09 06:00:00  27394.188498  2016010906   2016_01M           31\n",
       "2 2016-01-09 12:00:00  33429.098094  2016010912   2016_01M           31\n",
       "3 2016-01-09 18:00:00  33316.666473  2016010918   2016_01M           31\n",
       "0 2016-02-05 01:00:00  30132.111645  2016020501   2016_02M           29"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_identifier = 'M'\n",
    "median_data['timestamp'] = median_data['date'].dt.strftime('%Y%m%d%H')\n",
    "median_data['TIMESERIES'] = median_data['date'].dt.strftime('%Y_%m{}'.format(median_identifier))\n",
    "median_data['daysinmonth'] = median_data['date'].dt.daysinmonth\n",
    "median_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = median_data[['timestamp', 'TIMESERIES', 'daysinmonth']]\n",
    "tp2 = peak_data[['timestamp', 'TIMESERIES', 'daysinmonth']]\n",
    "timepoints_tab = pd.concat([tp1, tp2])\n",
    "timepoints_tab.index.name = 'timepoint_id'\n",
    "tmp = timepoints_tab.reset_index(drop=True)\n",
    "tmp = tmp.rename(columns={'TIMESERIES':'timeseries'})\n",
    "tmp.index += 1  # To start on 1\n",
    "tmp.index.name = 'timepoint_id'\n",
    "tmp[['timestamp', 'timeseries']].to_csv('switch-inputs/timepoints.tab', sep='\\t')\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# Todo implement multiple periods based on the data\n",
    "d = OrderedDict({'INVESTMENT_PERIOD': [2016], 'period_start': [2015], 'period_end':[2025]})\n",
    "periods_tab = pd.DataFrame(d)\n",
    "periods_tab= periods_tab.set_index('INVESTMENT_PERIOD')\n",
    "periods_tab.to_csv('switch-inputs/periods.tab', sep='\\t')\n",
    "periods_tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_tab = timepoints_tab[['TIMESERIES', 'daysinmonth']].drop_duplicates('TIMESERIES').reset_index(drop=True)\n",
    "ts_duration_of_tp = (24/number)\n",
    "timeseries_tab['ts_period'] = 2016 # Fix this to change investment period\n",
    "timeseries_tab['count'] = timeseries_tab.groupby('ts_period')['TIMESERIES'].transform(len)\n",
    "timeseries_tab['ts_duration_of_tp'] = ts_duration_of_tp\n",
    "timeseries_tab['ts_num_tps'] = timepoints_tab[['timestamp', 'TIMESERIES']].groupby('TIMESERIES').count().values\n",
    "timeseries_tab['ts_scale_to_period'] = 10*24*(365/(timeseries_tab['count']))/(timeseries_tab['ts_duration_of_tp']*timeseries_tab['ts_num_tps'])\n",
    "timeseries_tab.index +=1\n",
    "timeseries_tab.index.name = 'timepoint_id'\n",
    "del timeseries_tab['daysinmonth']\n",
    "del timeseries_tab['count']\n",
    "timeseries_tab.to_csv('switch-inputs/timeseries.tab', index=False, sep='\\t')\n",
    "timeseries_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement security check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = '../data/clean/SWITCH/'\n",
    "ren_cap_data = pd.read_csv(data_path + 'ren-all.csv', index_col=0, parse_dates=True)\n",
    "ren_cap_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renewable_plants = len(ren_cap_data.GENERATION_PROJECT.unique())\n",
    "renewable_plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = set(peak_data.date.dt.year)\n",
    "periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the generation using the filter dates\n",
    "filter_dates = pd.DatetimeIndex(pd.concat([peak_data, median_data])['date'].reset_index(drop=True))\n",
    "df = pd.DataFrame([])\n",
    "ren_tmp = ren_cap_data.copy()\n",
    "ren_tmp.index = ren_tmp.index + pd.DateOffset(years=2)\n",
    "#df = df.append(ren_tmp)\n",
    "for year in periods:\n",
    "    df = df.append(ren_tmp)\n",
    "    ren_tmp.index = ren_tmp.index + pd.DateOffset(years=1)\n",
    "grouped = df.loc[filter_dates].dropna().reset_index(drop=True).groupby('GENERATION_PROJECT', as_index=False)\n",
    "tmp = []\n",
    "for name, group in grouped:\n",
    "    tmp.append(group.reset_index(drop=True))\n",
    "variable_cap = pd.concat(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"switch-inputs/variable_capacity_factors.tab\")\n",
    "variable_tab = variable_cap.groupby('GENERATION_PROJECT')\n",
    "for keys in variable_tab.groups.keys():\n",
    "    data = variable_tab.get_group(keys).reset_index(drop=True)\n",
    "    data.index +=1\n",
    "    data.index.name = 'timepoint'\n",
    "    data.rename(columns={'capacity_factor': 'gen_max_capacity_factor'},\n",
    "               inplace=True)\n",
    "    data.reset_index()[['GENERATION_PROJECT', 'timepoint', 'gen_max_capacity_factor']].to_csv('switch-inputs/variable_capacity_factors.tab', \n",
    "                                                                  sep='\\t', index=False, \n",
    "                mode='a', header=(not os.path.exists('switch-inputs/variable_capacity_factors.tab')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_tmp = loads[loads.year <= 2025]\n",
    "list_tmp = []\n",
    "tmp = (loads_tmp.loc[pd.concat([peak_data, median_data])['date']].drop(['year', 'month','day','hour', 'total'], axis=1).reset_index()\n",
    "        .drop_duplicates('index').reset_index(drop=True))\n",
    "del tmp['index']\n",
    "tmp = tmp.unstack(0)\n",
    "for name, group in tmp.groupby(level=0):\n",
    "    list_tmp.append(group.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_tab = pd.concat(list_tmp)\n",
    "loads_tab;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_tab = pd.concat(list_tmp)\n",
    "loads_tab.index += 1\n",
    "loads_tab = loads_tab.rename(columns={'level_0':'LOAD_ZONE', 0:'zone_demand_mw'})\n",
    "del loads_tab['level_1']\n",
    "loads_tab.index.name = 'TIMEPOINT'\n",
    "loads_tab = loads_tab.reset_index()[['LOAD_ZONE', 'TIMEPOINT', 'zone_demand_mw']]\n",
    "loads_tab.to_csv('switch-inputs/loads.tab', sep='\\t', index=False)\n",
    "loads_tab;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = 'P'\n",
    "output_data['timestamp'] = output_data['date'].dt.strftime('%Y%m%d%H')\n",
    "output_data['TIMESERIES'] = output_data['date'].dt.strftime('%Y_%m{}'.format(identifier))\n",
    "output_data['daysinmonth'] = output_data['date'].dt.daysinmonth\n",
    "output_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints_tab = output_data[['timestamp', 'TIMESERIES', 'daysinmonth']]\n",
    "timepoints_tab.index.name = 'timepoint_id'\n",
    "tmp = timepoints_tab.reset_index(drop=True)\n",
    "tmp = tmp.rename(columns={'TIMESERIES':'timeseries'})\n",
    "tmp.index += 1  # To start on 1\n",
    "tmp.index.name = 'timepoint_id'\n",
    "tmp[['timestamp', 'timeseries']].to_csv('switch-inputs/timepoints.tab', sep='\\t')\n",
    "tmp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# Todo implement multiple periods based on the data\n",
    "d = OrderedDict({'INVESTMENT_PERIOD': [2016], 'period_start': [2015], 'period_end':[2025]})\n",
    "periods_tab = pd.DataFrame(d)\n",
    "periods_tab= periods_tab.set_index('INVESTMENT_PERIOD')\n",
    "periods_tab.to_csv('switch-inputs/periods.tab', sep='\\t')\n",
    "periods_tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_tab = timepoints_tab[['TIMESERIES', 'daysinmonth']].drop_duplicates('TIMESERIES').reset_index(drop=True)\n",
    "ts_duration_of_tp = 6#(24/len(output_data))\n",
    "timeseries_tab['ts_period'] = 2016 # Fix this to change investment period\n",
    "timeseries_tab['count'] = timeseries_tab.groupby('ts_period')['TIMESERIES'].transform(len)\n",
    "timeseries_tab['ts_duration_of_tp'] = ts_duration_of_tp\n",
    "timeseries_tab['ts_num_tps'] = output_data[['timestamp', 'TIMESERIES']].groupby('TIMESERIES').count().values\n",
    "timeseries_tab['ts_scale_to_period'] = 10*24*(365/(timeseries_tab['count']))/(timeseries_tab['ts_duration_of_tp']*timeseries_tab['ts_num_tps'])\n",
    "timeseries_tab.index +=1\n",
    "timeseries_tab.index.name = 'timepoint_id'\n",
    "del timeseries_tab['daysinmonth']\n",
    "del timeseries_tab['count']\n",
    "timeseries_tab.to_csv('switch-inputs/timeseries.tab', index=False, sep='\\t')\n",
    "timeseries_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable capacity factor  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = '../data/clean/SWITCH/'\n",
    "ren_cap_data = pd.read_csv(data_path + 'ren-all.csv', index_col=0, parse_dates=True)\n",
    "ren_cap_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renewable_plants = len(ren_cap_data.GENERATION_PROJECT.unique())\n",
    "renewable_plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ren_cap_data_year = ren_cap_data.index.year.unique()\n",
    "ren_cap_data_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = set(pek_da.date.dt.year)\n",
    "periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the generation using the filter dates\n",
    "filter_dates = pd.DatetimeIndex(output_data['date'].reset_index(drop=True))\n",
    "df = pd.DataFrame([])\n",
    "ren_tmp = ren_cap_data.copy()\n",
    "ren_tmp.index = ren_tmp.index + pd.DateOffset(years=2)\n",
    "#df = df.append(ren_tmp)\n",
    "for year in periods:\n",
    "    df = df.append(ren_tmp)\n",
    "    ren_tmp.index = ren_tmp.index + pd.DateOffset(years=1)\n",
    "grouped = df.loc[filter_dates].dropna().reset_index(drop=True).groupby('GENERATION_PROJECT', as_index=False)\n",
    "tmp = []\n",
    "for name, group in grouped:\n",
    "    tmp.append(group.reset_index(drop=True))\n",
    "variable_cap = pd.concat(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"switch-inputs/variable_capacity_factors.tab\")\n",
    "variable_tab = variable_cap.groupby('GENERATION_PROJECT')\n",
    "for keys in variable_tab.groups.keys():\n",
    "    data = variable_tab.get_group(keys).reset_index(drop=True)\n",
    "    data.index +=1\n",
    "    data.index.name = 'timepoint'\n",
    "    data.rename(columns={'capacity_factor': 'gen_max_capacity_factor'},\n",
    "               inplace=True)\n",
    "    data.reset_index()[['GENERATION_PROJECT', 'timepoint', 'gen_max_capacity_factor']].to_csv('switch-inputs/variable_capacity_factors.tab', \n",
    "                                                                  sep='\\t', index=False, \n",
    "                mode='a', header=(not os.path.exists('switch-inputs/variable_capacity_factors.tab')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_tmp = loads[loads.year <= 2025]\n",
    "list_tmp = []\n",
    "tmp = (loads_tmp.loc[output_data['date']].drop(['year', 'month','day','hour', 'total'], axis=1).reset_index()\n",
    "        .drop_duplicates('index').reset_index(drop=True))\n",
    "del tmp['index']\n",
    "tmp = tmp.unstack(0)\n",
    "for name, group in tmp.groupby(level=0):\n",
    "    list_tmp.append(group.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_tab = pd.concat(list_tmp)\n",
    "loads_tab;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_tab = pd.concat(list_tmp)\n",
    "loads_tab.index += 1\n",
    "loads_tab = loads_tab.rename(columns={'level_0':'LOAD_ZONE', 0:'zone_demand_mw'})\n",
    "del loads_tab['level_1']\n",
    "loads_tab.index.name = 'TIMEPOINT'\n",
    "loads_tab = loads_tab.reset_index()[['LOAD_ZONE', 'TIMEPOINT', 'zone_demand_mw']]\n",
    "loads_tab.to_csv('switch-inputs/loads.tab', sep='\\t', index=False)\n",
    "loads_tab;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
